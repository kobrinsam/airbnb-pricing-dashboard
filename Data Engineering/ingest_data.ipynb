{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Airbnb Data and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3 will initialize connection using environment variables\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create functions\n",
    "#### 2.1 Function to retrieve URLs for listings, reviews, and geospatial data from Inside Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to download Inside Airbnb page and get URLs for desired file types and market\n",
    "def download_airbnb_urls(market):\n",
    "    url = \"https://insideairbnb.com/get-the-data/\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        links = soup.find_all('a', href=True)\n",
    "        urls = []\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            # Check if the link ends with .csv.gz or .geojson and contains the market name\n",
    "            if (href.endswith('.csv.gz') or href.endswith('.geojson')) and market.lower() in href.lower():\n",
    "                # Exclude links that contain 'calendar.csv.gz'\n",
    "                if 'calendar.csv.gz' not in href:\n",
    "                    urls.append(href)\n",
    "        return urls\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to download Inside Airbnb page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Function to download data from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(market, urls):\n",
    "    print(f'Download starting for {market}')\n",
    "    \n",
    "    data = {} # store downloaded data in a dictionary\n",
    "    for url in urls:\n",
    "        print(f\"Downloading file from: {url}\")\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                data[url] = response.content\n",
    "            else:\n",
    "                print(f\"Failed to download data from {url}. Status code: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred while downloading {url}: {str(e)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Function to upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(data, bucket_name, market_name):\n",
    "    print('Upload starting...')\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "    # s3_key represents unique identifier for the file in S3\n",
    "    for key, value in data.items():\n",
    "        # Extract filename from URL\n",
    "        filename = key.rsplit('/', 1)[-1]\n",
    "        \n",
    "        if filename == 'listings.csv.gz':\n",
    "            s3_key = f\"raw/listings/{market_name}-listings.csv.gz\"\n",
    "        elif filename == 'neighbourhoods.geojson':\n",
    "            s3_key = f\"raw/geospatial/{market_name}-neighbourhoods.geojson\"\n",
    "        elif filename == 'reviews.csv.gz':\n",
    "            s3_key = f\"raw/reviews/{market_name}-reviews.csv.gz\"\n",
    "\n",
    "        s3.put_object(Bucket=bucket_name, Key=s3_key, Body=value)\n",
    "        print(f\"Data uploaded to S3 bucket '{bucket_name}' with key '{s3_key}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ingest and upload market data to S3 bucket\n",
    "Estimated time to download market data and upload is 15 to 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download starting for albany\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/albany/2024-06-07/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/albany/2024-06-07/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/albany/2024-06-07/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/albany-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/albany-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/albany-neighbourhoods.geojson'\n",
      "Download starting for los-angeles\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/los-angeles/2024-06-07/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/los-angeles/2024-06-07/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/los-angeles/2024-06-07/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/los-angeles-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/los-angeles-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/los-angeles-neighbourhoods.geojson'\n",
      "Download starting for san-francisco\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/san-francisco/2024-06-04/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/san-francisco/2024-06-04/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ca/san-francisco/2024-06-04/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/san-francisco-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/san-francisco-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/san-francisco-neighbourhoods.geojson'\n",
      "Download starting for new-york-city\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/new-york-city/2024-07-05/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/new-york-city/2024-07-05/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/ny/new-york-city/2024-07-05/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/new-york-city-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/new-york-city-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/new-york-city-neighbourhoods.geojson'\n",
      "Download starting for chicago\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/il/chicago/2024-06-21/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/il/chicago/2024-06-21/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/il/chicago/2024-06-21/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/chicago-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/chicago-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/chicago-neighbourhoods.geojson'\n",
      "Download starting for seattle\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/wa/seattle/2024-06-24/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/wa/seattle/2024-06-24/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/wa/seattle/2024-06-24/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/seattle-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/seattle-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/seattle-neighbourhoods.geojson'\n",
      "Download starting for washington-dc\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/dc/washington-dc/2024-06-21/data/listings.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/dc/washington-dc/2024-06-21/data/reviews.csv.gz\n",
      "Downloading file from: https://data.insideairbnb.com/united-states/dc/washington-dc/2024-06-21/visualisations/neighbourhoods.geojson\n",
      "Upload starting...\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/listings/washington-dc-listings.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/reviews/washington-dc-reviews.csv.gz'\n",
      "Data uploaded to S3 bucket 'airbnb-capstone-project' with key 'raw/geospatial/washington-dc-neighbourhoods.geojson'\n"
     ]
    }
   ],
   "source": [
    "markets = ['albany','los-angeles','san-francisco','new-york-city','chicago','seattle','washington-dc']\n",
    "\n",
    "for market in markets:\n",
    "    # Retrieve URLs for Inside Airbnb data\n",
    "    source_urls = download_airbnb_urls(market)\n",
    "\n",
    "    # Download data from doanloaded URLs\n",
    "    data = download_data(market, source_urls)\n",
    "\n",
    "    # Upload data to S3\n",
    "    # S3 bucket and prefix where you want to upload the data\n",
    "    bucket_name = 'airbnb-capstone-project'\n",
    "    s3_prefix = market\n",
    "    upload_to_s3(data, bucket_name, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Delete downloaded data\n",
    "Delete data downloaded onto local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
